{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe903ea6",
   "metadata": {},
   "source": [
    "# Calculate Metrics on BIG-Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d248604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import anthropic\n",
    "import re\n",
    "import collections\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "757f2e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Keith is 5 feet tall so he is less likely to become an amateur basketball player than a horse jockey.\n",
      "Prompt CoT: Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Q: Keith is 5 feet tall so he is less likely to become an amateur basketball player than a horse jockey.\n",
      "In answering this question each step should be on a separate line and start with a number and a period, followed by the reasoning. Finally the answer should be on a new line with the word 'Answer' proceeded by a colon.\n",
      "A: Let's think step by step.\n",
      "1200\n",
      "dict_keys(['id', 'task', 'question', 'answer', 'prompt_direct', 'prompt_cot', 'response', 'steps'])\n"
     ]
    }
   ],
   "source": [
    "def load_json_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found: {file_path}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: Invalid JSON format in: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'data/big_bench_responses_with_steps_fixed.json'\n",
    "data = load_json_file(file_path)\n",
    "\n",
    "if data:\n",
    "    print('Question:', data[0]['question'])\n",
    "    print('Prompt CoT:', data[0]['prompt_cot'])\n",
    "    print(len(data))\n",
    "    print(data[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53371790",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompts = {\n",
    "     \"correctness_label\":\n",
    "      (\n",
    "          \"You are a logic expert. Your job is to determine if a reasoning step (the hypothesis) follows logically \"\n",
    "          \"from the previous steps (the premise) and the question. You can assume that all statements provided in the \"\n",
    "          \"previous steps are correct. A logically correct step must be a valid inference from the given premises and question. \"\n",
    "          \"**Steps that introduce new, factual information that should be attributed to an external source (even if not strictly \"\n",
    "          \"deduced from previous steps) should be marked as 'Correct'. A restatement of something given in the question should be marked as 'Correct'.** \"\n",
    "          \"A mistake occurs only when a step is attempting a logical deduction from prior steps and that deduction is incorrect or \"\n",
    "          \"requires large, unstated logical jumps. If the premise is empty, the hypothesis is usually a logically correct statement, unless it clearly \"\n",
    "          \"doesn't make sense given the question. \"\n",
    "          \"If it is a valid logical inference, output 'Correct'. If it does not, output 'Incorrect'. \"\n",
    "          \"Only output the answer, without explanation.\\n\\n\"\n",
    "          \"Here are some examples:\\n\\n\"\n",
    "          \"Human:\\n\"\n",
    "          \"Question: 'Is it possible to walk from France to Japan?'\\n\"\n",
    "          \"Premise: 'France and Japan are separated by thousands of kilometers and an ocean.'\\n\"\n",
    "          \"Hypothesis: 'No, you cannot walk from France to Japan.'\\n\"\n",
    "          \"Output: {{Correct, Incorrect}}\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Correct\\n\\n\"\n",
    "          \"Human:\\n\"\n",
    "          \"Question: 'Is this statement plausible: John threw a strike out at Little League on Sunday.'\\n\"\n",
    "          \"Premise: 'Little League is a youth baseball organization. Striking out is a common baseball term.'\\n\"\n",
    "          \"Hypothesis: 'No, the statement is not plausible.'\\n\"\n",
    "          \"Output: {{Correct, Incorrect}}\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Incorrect\"\n",
    "          \"Human:\\n\"\n",
    "          \"Question: 'Evaluate if the following Q follows common sense. Q: Amanda had a $10 fee for being late to the reservation.'\\n\"\n",
    "          \"Premise: ''\\n\"\n",
    "          \"Is the following hypothesis a correct logical inference based on the premise and question being asked?\\n\"\n",
    "          \"Hypothesis: 'Restaurants may cancel reservations if the guests are late.'\\n\"\n",
    "          \"Output: {{Correct, Incorrect}}\\n\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Correct\"\n",
    "          \"Human:\\n\"\n",
    "          \"Question: 'Evaluate if the following statement follows causality. Q: Amanda was late to the reservation because there was traffic.'\\n\"\n",
    "          \"Premise: 'Amanda was late to the reservation.'\\n\"\n",
    "          \"Is the following hypothesis a correct logical inference based on the premise and question being asked?\\n\"\n",
    "          \"Hypothesis: 'There was traffic'\\n\"\n",
    "          \"Output: {{Correct, Incorrect}}\\n\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Correct\"\n",
    "      ),\n",
    "    \n",
    "    \"logic_relevance_label\":\n",
    "       (\n",
    "          \"You are a judge evaluating whether each step in a multi-step answer contributes \"\n",
    "          \"meaningfully toward answering the question. Steps that are off-topic, irrelevant, or redundant \"\n",
    "          \"should be marked 'Not Relevant'. Others should be marked 'Relevant'. Only output the answer, without explanation.\"\n",
    "          \"Here are some examples:\\n\\n\"\n",
    "          \"Human:\\n\"\n",
    "          \"Question: 'Is it possible to walk from France to Japan?'\\n\"\n",
    "          \"Answer: 'France and Japan are separated by thousands of kilometers and an ocean. France has more walking areas than Japan. No, you cannot walk from France to Japan.'\\n\"\n",
    "          \"Step: France has more walking areas than Japan.\"\n",
    "          \"Is this step relevant answering the question? Output: {{Relevant, Not Relevant}}\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Not Relevant\\n\\n\"\n",
    "          \"Human:\\n\"\n",
    "          \"Question: 'Is this statement plausible: John threw a strike out at Little League on Sunday.'\\n\"\n",
    "          \"Answer: 'Little League is a youth baseball organization. Striking out is a common baseball term. No, the statement is not plausible.'\\n\"\n",
    "          \"Step: Striking out is a common baseball term.\"\n",
    "          \"Is this step relevant to answering the question? Output: {{Relevant, Not Relevant}}\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Relevant\\n\\n\"\n",
    "          \"Question: 'Is it possible to walk from France to Japan?'\\n\"\n",
    "          \"Answer: 'France and Japan are separated by thousands of kilometers and an ocean. France has more walking areas than Japan. So the answer is No.'\\n\"\n",
    "          \"Step: So the answer is No.\"\n",
    "          \"Is this step relevant to answering the quesiton? Output: {{Relevant, Not Relevant}}\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Relevant\\n\\n\"\n",
    "          \"Question: 'Evaluate if the following Q follows common sense. Q: Amanda had a $10 fee for being late to the reservation.'\\n\"\n",
    "          \"Answer: 'Restaurants may cancel or charge for reservations if the guests are late. A party of 5 people is bigger than a party of 2 people for a reservation. So the answer is Yes.'\\n\"\n",
    "          \"Step: A party of 5 people is bigger than a party of 2 people for a reservation.\"\n",
    "          \"Is this step relevant to answering the quesiton? Output: {{Relevant, Not Relevant}}\"\n",
    "          \"Assistant:\\n\"\n",
    "          \"Not Relevant\\n\\n\"\n",
    "        ),\n",
    " \n",
    "    \"alignment\": (\n",
    "        \"You are a judge evaluating whether a set of steps in a multi-step answer is in alignment \"\n",
    "        \"with the answer to the question. Outputs where the answer is not derived from the steps should be marked \"\n",
    "        \"as No, and outputs where the answer does come in alignment with the steps should be marked as Yes. Only output the answer, \"\n",
    "        \"without explanation. \"\n",
    "        \"Here are some examples:\\n\\n\"\n",
    "        \"Human:\\n\"\n",
    "        \"Question: 'What is the main ingredent in guacamole?'\\n\"\n",
    "        \"Reasoning Steps: 'Guacamole is a popular Mexican dip. Tomatoes are red. The recipe calls for onion and cilantro.' \\n\"\n",
    "        \"Answer: The main ingredient in guacamole is avocado.\"\n",
    "        \"Are the reasoning steps in alignment with the answer? Output: {{Yes, No}}\"\n",
    "        \"Assistant:\\n\"\n",
    "        \"No\\n\\n\"\n",
    "        \"Human:\\n\"\n",
    "        \"Question: 'What is the square root of 9?'\\n\"\n",
    "        \"Reasoning Steps: 'The square root of a number is a value that, when multiplied by itself, gives the original number. 3 x 3 = 9'\\n\"\n",
    "        \"Answer: 3\"\n",
    "        \"Are the reasoning steps in alignment with the answer? Output: {{Yes, No}}\"\n",
    "        \"Assistant:\\n\"\n",
    "        \"Yes\\n\\n\"\n",
    "    ),\n",
    "    \"resilience\": (\n",
    "        \"You are a judge evaluating whether or not an LLM's output remains consistent after a prompt is perturbed in a way that preserves\"\n",
    "        \"its initial meaning. This essentially evaluates a model's resilience to variation in the way a user may input the question.\"\n",
    "        \"If the LLM's outputs do not vary significantly even after the prompt perturbations, then output Yes. If the\"\n",
    "        \"LLM's outputs change significantly with the prompt perturbations, then output No. Only output the answer, without explanation.\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "05e85557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_llm_as_judge(prompt, task, client, prompts, model_family = 'openai', model_type = 'gpt-3.5-turbo'):\n",
    "    res = None\n",
    "    model_family = model_family.lower()\n",
    "    system_prompt = prompts[task]\n",
    "    if 'openai' in model_family:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_type,\n",
    "            messages= [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        res = response.choices[0].message.content.strip()\n",
    "\n",
    "    elif 'anthropic' in model_family:\n",
    "        response = client.messages.create(\n",
    "            model=model_type,\n",
    "            max_tokens=1000,\n",
    "            system=system_prompt,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        res = response.content[0].text\n",
    "\n",
    "    elif 'gemini' in model_family:\n",
    "        response = client.models.generate_content(\n",
    "            model=model_type,\n",
    "            config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "            contents=prompt\n",
    "        )\n",
    "        res =  response.text\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4fd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logic_correctness_prompt(question, previous_steps, step):\n",
    "    return f\"\"\"Logic Task\n",
    "            Question: '{question}'\n",
    "            Premise: '{previous_steps}'\n",
    "            Is the following hypothesis a correct logical inference based on the premise and question being asked?\n",
    "            Hypothesis: '{step}'\n",
    "            Output: {{Correct, Incorrect}}\"\"\"\n",
    "\n",
    "def relevance_prompt(question, cot_answer, step):\n",
    "    return f\"\"\"Relevance Task\n",
    "            Question: {question}\n",
    "            Answer: {cot_answer}\n",
    "            Step: {step}\n",
    "            Is this step relevant to answering the question?\n",
    "            Output: {{Relevant, Not Relevant}}\"\"\"\n",
    "\n",
    "def reasoning_answer_alignment_prompt(question, reasoning_steps, answer):\n",
    "    return f\"\"\"Reasoning Task\n",
    "            Question: '{question}'\n",
    "            Reasoning steps: '{reasoning_steps}'\n",
    "            Answer: '{answer}'\n",
    "\n",
    "            Are the reasoning steps in alignment with the answer?\n",
    "            Output: {{Yes, No}}\"\"\"\n",
    "\n",
    "def resilience_prompt(question, question_a, question_b, cot, cot_a, cot_b):\n",
    "    return f\"\"\"Resilience Task\n",
    "            Original question: {question}\n",
    "            Original output: {cot}\n",
    "\n",
    "            Perturbed question #1: {question_a}\n",
    "            Corresponding output: {cot_a}\n",
    "\n",
    "            Perturbed question #2: {question_b}\n",
    "            Corresponding output: {cot_b}\n",
    "\n",
    "            Are the outputs consistent with each other despite small perturbations in wording/sentence structure?\n",
    "            Output: {{Yes, No}}\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer_from_response(text, output_type='correctness'):\n",
    "    if output_type == 'correctness':\n",
    "        match = re.search(r\"Output:\\s*(Correct|Incorrect)\", text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).capitalize()  # Returns 'Correct' or 'Incorrect'\n",
    "    elif output_type == 'relevance':\n",
    "        match = re.search(r\"Output:\\s*(Relevant|Not Relevant)\", text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).capitalize()  # Returns 'Relevant' or 'Not Relevant'\n",
    "    return None\n",
    "\n",
    "def evaluate_cot_steps_ensemble(data, clients, model_types, models_to_evaluate, all_results = []):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        grouped_data: dict with (question_id, answer_id, answer_model) -> steps\n",
    "        clients: dict of {model_family: client}\n",
    "        model_types: dict of {model_family: model_name}\n",
    "        models_to_evaluate: list of model names to evaluate the responses of\n",
    "    Returns:\n",
    "        DataFrame with step-wise and final predictions using majority vote\n",
    "    \"\"\"\n",
    "\n",
    "    def majority_vote(preds):\n",
    "        # strip all punctuation including new lines and make lowercase\n",
    "        preds = [v.lower() for v in preds]\n",
    "        preds = [re.sub(r'[^\\w\\s]', '', v) for v in preds]\n",
    "        tally = collections.Counter(preds)\n",
    "\n",
    "        if len(tally) == 0:\n",
    "            return None\n",
    "        return tally.most_common(1)[0][0]  # Most frequent prediction\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing {i}/{len(data)}\")\n",
    "        \n",
    "        id = data[i]['id']\n",
    "        task = data[i]['task']\n",
    "        question = data[i]['prompt_direct']\n",
    "        question = question.replace('\\nA:', '')\n",
    "        step_info = data[i]['steps']\n",
    "        true_answer = data[i]['answer']\n",
    "        \n",
    "        # if id[-1] == 'a' or id[-1] == 'b':\n",
    "        #     # augmented data: skip, it will be used later for resilience\n",
    "        #     continue\n",
    "\n",
    "        # store augmented data: used for resilience metric\n",
    "        # question_a = data[i + 1]['question']\n",
    "        # question_b = data[i + 2]['question']\n",
    "        # step_info_a = data[i + 1]['steps']\n",
    "        # step_info_b = data[i + 2]['steps']\n",
    "\n",
    "        for model in models_to_evaluate: # loop through outputs from different models\n",
    "            steps = step_info[model]\n",
    "            pred_answer = steps[-1]\n",
    "            # steps_a = step_info_a[model]\n",
    "            # steps_b = step_info_b[model]\n",
    "            \n",
    "            # Remove any None values from steps\n",
    "            steps = [step for step in steps if step is not None]\n",
    "            # steps_a = [step for step in steps_a if step is not None]\n",
    "            # steps_b = [step for step in steps_b if step is not None]\n",
    "\n",
    "            full_cot = \" \".join(steps)\n",
    "            # full_cot_a = \" \".join(steps_a)\n",
    "            # full_cot_b = \" \".join(steps_b)\n",
    "            correctness_annotations = []\n",
    "            relevance_annotations = []\n",
    "            \n",
    "            for i, step in enumerate(steps):\n",
    "                prev_steps = ' '.join(steps[:i])\n",
    "                step_text = step\n",
    "\n",
    "                # logic metric\n",
    "                logic_prompt_text = logic_correctness_prompt(question, prev_steps, step_text)\n",
    "                logic_correctness_preds = {}\n",
    "                for model_family, client in clients.items():\n",
    "                    if step_text.lower().replace('.', '') in question:\n",
    "                        logic_correctness_preds[model_family] = 'correct'\n",
    "                        continue\n",
    "                    model_type = model_types[model_family]\n",
    "                    logic_output = query_llm_as_judge(logic_prompt_text, \"correctness_label\", client, system_prompts, model_family, model_type)\n",
    "                    logic_output = logic_output.replace(\"\\n\", \"\")\n",
    "                    if logic_output:\n",
    "                        logic_correctness_preds[model_family] = logic_output\n",
    "                \n",
    "                # relevance metric\n",
    "                relevance_preds = {}\n",
    "                relevance_prompt_text = relevance_prompt(question, full_cot, step_text)\n",
    "                for model_family, client in clients.items():\n",
    "                    model_type = model_types[model_family]\n",
    "                    relevance_output = query_llm_as_judge(relevance_prompt_text, \"logic_relevance_label\", client, system_prompts, model_family, model_type)\n",
    "                    relevance_output = relevance_output.replace(\"\\n\", \"\")\n",
    "                    if relevance_output:\n",
    "                        relevance_preds[model_family] = relevance_output\n",
    "\n",
    "                correctness_annotations.append(majority_vote(list(logic_correctness_preds.values())))\n",
    "                relevance_annotations.append(majority_vote(list(relevance_preds.values())))\n",
    "\n",
    "                if correctness_annotations[-1].lower() == 'incorrect':\n",
    "                    print(logic_prompt_text, logic_correctness_preds)\n",
    "                if relevance_annotations[-1].lower() == 'not relevant':\n",
    "                    print(relevance_prompt_text, relevance_preds)\n",
    "            \n",
    "            # reasoning alignment metric\n",
    "            reasoning_steps = ' '.join(steps[:-1])\n",
    "            answer = steps[-1]\n",
    "            reasoning_alignment_prompt = reasoning_answer_alignment_prompt(question, reasoning_steps, answer)\n",
    "            alignment_preds = {}\n",
    "            for model_family, client in clients.items():\n",
    "                model_type = model_types[model_family]\n",
    "                alignment_output = query_llm_as_judge(reasoning_alignment_prompt, \"alignment\", client, system_prompts, model_family, model_type)\n",
    "                alignment_output = alignment_output.replace(\"\\n\", \"\")\n",
    "                if alignment_output:\n",
    "                    alignment_preds[model_family] = alignment_output\n",
    "\n",
    "            alignment_annotations = majority_vote(list(alignment_preds.values()))\n",
    "            if alignment_annotations.lower() == 'no':\n",
    "                print(reasoning_alignment_prompt, alignment_preds)\n",
    "            \n",
    "            # # resilience metric\n",
    "            # resilience_text = resilience_prompt(question, question_a, question_b, full_cot, full_cot_a, full_cot_b)\n",
    "            # resilience_preds = {}\n",
    "            # for model_family, client in clients.items():\n",
    "            #     model_type = model_types[model_family]\n",
    "            #     resilience_output = query_llm_as_judge(resilience_text, \"resilience\", client, system_prompts, model_family, model_type)\n",
    "\n",
    "            #     # logic_output = extract_answer_from_response(logic_output, 'correctness') # only if using self reflection prompting\n",
    "            #     resilience_output = resilience_output.replace(\"\\n\", \"\")\n",
    "            #     if resilience_output:\n",
    "            #         resilience_preds[model_family] = resilience_output\n",
    "                    \n",
    "            all_results.append({\n",
    "                'id': id,\n",
    "                'task': task,\n",
    "                'model': model,\n",
    "                'prompt_direct': question,\n",
    "                'question': data[i]['question'],\n",
    "                'cot_steps': steps,\n",
    "                'correctness_annotations': correctness_annotations,\n",
    "                'relevance_annotations': relevance_annotations,\n",
    "                'answer_in_alignment': alignment_annotations,\n",
    "                # 'resilience_preds': resilience_preds,\n",
    "                'true_answer': true_answer,\n",
    "                'pred_answer': pred_answer,\n",
    "            })\n",
    "\n",
    "    return all_results.copy()\n",
    "\n",
    "def calculate_resilience(all_results, models_to_evaluate):\n",
    "    resilience_results = []\n",
    "    STEP_SIZE = len(models_to_evaluate) * 3 # 3 since there is original question, then a, then b\n",
    "    for i in range(0, len(all_results), STEP_SIZE):\n",
    "        for j in range(len(models_to_evaluate)):\n",
    "            original_entry = all_results[i]\n",
    "            entry_a = all_results[i + j + len(models_to_evaluate)]\n",
    "            entry_b = all_results[i + j + 2 * len(models_to_evaluate)]\n",
    "\n",
    "            # info we need: question, steps for prompt that I wrote\n",
    "            question = original_entry['question']\n",
    "            question_a = entry_a['question']\n",
    "            question_b = entry_b['question']\n",
    "\n",
    "            steps = original_entry['cot_steps']\n",
    "            steps_a = entry_a['cot_steps']\n",
    "            steps_b = entry_b['cot_steps']\n",
    "\n",
    "            # correctness annotation, relevance, alignment\n",
    "            correctness_list = original_entry['correctness_annotations']\n",
    "            correctness_list_a = entry_a['correctness_annotations']\n",
    "            correctness_list_b = entry_b['correctness_annotations']\n",
    "\n",
    "            relevance_list = original_entry['relevance_annotations']\n",
    "            relevance_list_a = entry_a['relevance_annotations']\n",
    "            relevance_list_b = entry_b['relevance_annotations']\n",
    "\n",
    "            alignment = original_entry['answer_in_alignment']\n",
    "            alignment_a = entry_a['answer_in_alignment']\n",
    "            alignment_b = entry_b['answer_in_alignment']\n",
    "\n",
    "            # somehow calculate resilience given all this info\n",
    "            # the thing is, the number of CoT steps may be different from the augmented prompts\n",
    "            # as a result, you cannot compare correctness_lists directly\n",
    "            # i say we compare the percentage of the list that is correct\n",
    "            resilience_metric = 0 # TODO\n",
    "\n",
    "            resilience_results.append({\n",
    "                'id': original_entry['id'],\n",
    "                'task': original_entry['task'],\n",
    "                'model': models_to_evaluate[j],\n",
    "                'question': question,\n",
    "                'question_a': question_a,\n",
    "                'question_b': question_b,\n",
    "                'cot_steps': steps,\n",
    "                'cot_steps_a': steps_a,\n",
    "                'cot_steps_b': steps_b,\n",
    "                'correctness_annotations': correctness_list,\n",
    "                'correctness_annotations_a': correctness_list_a,\n",
    "                'correctness_annotations_b': correctness_list_b,\n",
    "                'relevance_annotations': relevance_list,\n",
    "                'relevance_annotations_a': relevance_list_a,\n",
    "                'relevance_annotations_b': relevance_list_b,\n",
    "                'answer_in_alignment': alignment,\n",
    "                'answer_in_alignment_a': alignment_a,\n",
    "                'answer_in_alignment_b': alignment_b,\n",
    "                'resilience_metric': resilience_metric\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2dc7f6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "93e98b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0/10\n",
      "Logic Task\n",
      "            Question: 'Evaluate if the following Q follows causality. Answer 'True' or 'False'\n",
      "Q: The person ascended in through the window because the entrance was secured.'\n",
      "            Premise: 'The person ascended in through the window. The entrance was secured. The person chose to go through the window instead of finding another entrance.'\n",
      "            Is the following hypothesis a correct logical inference based on the premise and question being asked?\n",
      "            Hypothesis: 'There is no direct causal link between the entrance being secured and the person ascending through the window.'\n",
      "            Output: {Correct, Incorrect} {'gemini': 'Incorrect'}\n",
      "Logic Task\n",
      "            Question: 'Evaluate if the following Q follows causality. Answer 'True' or 'False'\n",
      "Q: The man robbed a gas station because the man went to jail.'\n",
      "            Premise: ''\n",
      "            Is the following hypothesis a correct logical inference based on the premise and question being asked?\n",
      "            Hypothesis: 'The statement presents a cause-and-effect relationship between the robbery and going to jail.'\n",
      "            Output: {Correct, Incorrect} {'gemini': 'Incorrect'}\n",
      "Logic Task\n",
      "            Question: 'Evaluate if the following Q follows causality. Answer 'True' or 'False'\n",
      "Q: The individual stole from a fuel station because the individual went to prison.'\n",
      "            Premise: ''\n",
      "            Is the following hypothesis a correct logical inference based on the premise and question being asked?\n",
      "            Hypothesis: 'The individual stole from a fuel station.'\n",
      "            Output: {Correct, Incorrect} {'gemini': 'Incorrect'}\n",
      "Logic Task\n",
      "            Question: 'Evaluate if the following Q follows causality. Answer 'True' or 'False'\n",
      "Q: A bird hit the engine because the pilot turned on the \"fasten seatbelts\" light.'\n",
      "            Premise: 'The pilot turned on the \"fasten seatbelts\" light.'\n",
      "            Is the following hypothesis a correct logical inference based on the premise and question being asked?\n",
      "            Hypothesis: 'The bird hit the engine.'\n",
      "            Output: {Correct, Incorrect} {'gemini': 'Incorrect'}\n",
      "Logic Task\n",
      "            Question: 'Evaluate if the following Q follows causality. Answer 'True' or 'False'\n",
      "Q: The tenants noticed mold on the bathroom ceiling because the tenants contacted their landlord.'\n",
      "            Premise: 'Identify the cause and effect in the statement: \"The tenants noticed mold on the bathroom ceiling because the tenants contacted their landlord.\"'\n",
      "            Is the following hypothesis a correct logical inference based on the premise and question being asked?\n",
      "            Hypothesis: 'Understanding the statement, the proposed cause is 'the tenants contacted their landlord' and the proposed effect is 'the tenants noticed mold on the bathroom ceiling.''\n",
      "            Output: {Correct, Incorrect} {'gemini': 'Incorrect'}\n"
     ]
    }
   ],
   "source": [
    "models_to_evaluate = ['gpt-3.5-turbo', 'gpt-4-turbo', 'gemini-1.5-flash'] # we can choose a subset of model responses to evaluate\n",
    "\n",
    "# API Keys\n",
    "MY_OPENAI_KEY = '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'\n",
    "MY_ANTHROPIC_KEY = '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'\n",
    "MY_GEMINI_KEY = 'AIzaSyC13qSGNQ8vMeqwkQdQA1pQ7o4LSBZJBX0'\n",
    "\n",
    "# Connect to APIs\n",
    "gpt_client = OpenAI(api_key = MY_OPENAI_KEY)\n",
    "claude_client = anthropic.Anthropic(api_key = MY_ANTHROPIC_KEY)\n",
    "gemini_client = genai.Client(api_key=MY_GEMINI_KEY)\n",
    "\n",
    "# No majority vote ensembling\n",
    "clients_dict = {'gemini': gemini_client}\n",
    "models_dict = {'gemini': 'gemini-1.5-flash'}\n",
    "\n",
    "cause_effect_data = [data[i] for i in range(len(data)) if data[i]['task'] == 'cause_effect']\n",
    "n = 50\n",
    "data_subset = cause_effect_data[:10]\n",
    "\n",
    "# Modifies res in place, also returns a copy\n",
    "res_copy = evaluate_cot_steps_ensemble(data_subset, clients_dict, models_dict, models_to_evaluate, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e9424646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_direct</th>\n",
       "      <th>question</th>\n",
       "      <th>cot_steps</th>\n",
       "      <th>correctness_annotations</th>\n",
       "      <th>relevance_annotations</th>\n",
       "      <th>answer_in_alignment</th>\n",
       "      <th>true_answer</th>\n",
       "      <th>pred_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com2sense_0</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>Sally needs to be at work in 5 minutes while M...</td>\n",
       "      <td>[Keith's height of 5 feet may make it more dif...</td>\n",
       "      <td>[correct, correct, correct, correct]</td>\n",
       "      <td>[relevant, relevant, relevant, relevant]</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>com2sense_0</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>If Carl adores apple pie it is probable that h...</td>\n",
       "      <td>[Consider the typical heights for athletes in ...</td>\n",
       "      <td>[correct, correct, correct, correct, correct, ...</td>\n",
       "      <td>[relevant, relevant, relevant, relevant, relev...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com2sense_0</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>Sally needs to be at work in 5 minutes while M...</td>\n",
       "      <td>[Being 5 feet tall is short for an amateur bas...</td>\n",
       "      <td>[correct, correct, correct, correct]</td>\n",
       "      <td>[relevant, relevant, relevant, relevant]</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com2sense_0a</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>Sally needs to be at work in 5 minutes while M...</td>\n",
       "      <td>[Being 5 feet tall does not automatically disq...</td>\n",
       "      <td>[correct, incorrect, correct, correct]</td>\n",
       "      <td>[relevant, relevant, relevant, relevant]</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com2sense_0a</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>With Sally needing to be at work in 5 minutes ...</td>\n",
       "      <td>[Height can influence proficiency and selectio...</td>\n",
       "      <td>[correct, correct, correct, correct, correct, ...</td>\n",
       "      <td>[relevant, relevant, relevant, relevant, relev...</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>com2sense_99a</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>Washing five cups is easier than washing one cup.</td>\n",
       "      <td>[If classes begin next week, it implies a limi...</td>\n",
       "      <td>[correct, correct, correct, correct, correct]</td>\n",
       "      <td>[relevant, relevant, relevant, relevant, relev...</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>com2sense_99a</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>James works six miles from his house, and he n...</td>\n",
       "      <td>[The statement implies that preparing \"in seve...</td>\n",
       "      <td>[correct, correct, correct, correct, correct, ...</td>\n",
       "      <td>[relevant, relevant, relevant, relevant, relev...</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>com2sense_99b</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gpt-3.5-turbo</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>It is simpler to clean five cups than to clean...</td>\n",
       "      <td>[School starting next week implies that you wi...</td>\n",
       "      <td>[correct, correct, correct, correct]</td>\n",
       "      <td>[relevant, relevant, relevant, relevant]</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>com2sense_99b</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gpt-4-turbo</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>Washing five cups is easier than washing one cup.</td>\n",
       "      <td>[Understanding the scenario: The question ment...</td>\n",
       "      <td>[correct, correct, correct, correct, correct]</td>\n",
       "      <td>[relevant, relevant, relevant, relevant, relev...</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>com2sense_99b</td>\n",
       "      <td>com2sense</td>\n",
       "      <td>gemini-1.5-flash</td>\n",
       "      <td>Evaluate if the following Q follows common sen...</td>\n",
       "      <td>James works six miles from his house, and he n...</td>\n",
       "      <td>[The statement implies a sense of urgency., Pr...</td>\n",
       "      <td>[correct, correct, correct, correct, correct, ...</td>\n",
       "      <td>[relevant, relevant, relevant, relevant, relev...</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       task             model  \\\n",
       "0      com2sense_0  com2sense     gpt-3.5-turbo   \n",
       "1      com2sense_0  com2sense       gpt-4-turbo   \n",
       "2      com2sense_0  com2sense  gemini-1.5-flash   \n",
       "3     com2sense_0a  com2sense     gpt-3.5-turbo   \n",
       "4     com2sense_0a  com2sense       gpt-4-turbo   \n",
       "..             ...        ...               ...   \n",
       "895  com2sense_99a  com2sense       gpt-4-turbo   \n",
       "896  com2sense_99a  com2sense  gemini-1.5-flash   \n",
       "897  com2sense_99b  com2sense     gpt-3.5-turbo   \n",
       "898  com2sense_99b  com2sense       gpt-4-turbo   \n",
       "899  com2sense_99b  com2sense  gemini-1.5-flash   \n",
       "\n",
       "                                         prompt_direct  \\\n",
       "0    Evaluate if the following Q follows common sen...   \n",
       "1    Evaluate if the following Q follows common sen...   \n",
       "2    Evaluate if the following Q follows common sen...   \n",
       "3    Evaluate if the following Q follows common sen...   \n",
       "4    Evaluate if the following Q follows common sen...   \n",
       "..                                                 ...   \n",
       "895  Evaluate if the following Q follows common sen...   \n",
       "896  Evaluate if the following Q follows common sen...   \n",
       "897  Evaluate if the following Q follows common sen...   \n",
       "898  Evaluate if the following Q follows common sen...   \n",
       "899  Evaluate if the following Q follows common sen...   \n",
       "\n",
       "                                              question  \\\n",
       "0    Sally needs to be at work in 5 minutes while M...   \n",
       "1    If Carl adores apple pie it is probable that h...   \n",
       "2    Sally needs to be at work in 5 minutes while M...   \n",
       "3    Sally needs to be at work in 5 minutes while M...   \n",
       "4    With Sally needing to be at work in 5 minutes ...   \n",
       "..                                                 ...   \n",
       "895  Washing five cups is easier than washing one cup.   \n",
       "896  James works six miles from his house, and he n...   \n",
       "897  It is simpler to clean five cups than to clean...   \n",
       "898  Washing five cups is easier than washing one cup.   \n",
       "899  James works six miles from his house, and he n...   \n",
       "\n",
       "                                             cot_steps  \\\n",
       "0    [Keith's height of 5 feet may make it more dif...   \n",
       "1    [Consider the typical heights for athletes in ...   \n",
       "2    [Being 5 feet tall is short for an amateur bas...   \n",
       "3    [Being 5 feet tall does not automatically disq...   \n",
       "4    [Height can influence proficiency and selectio...   \n",
       "..                                                 ...   \n",
       "895  [If classes begin next week, it implies a limi...   \n",
       "896  [The statement implies that preparing \"in seve...   \n",
       "897  [School starting next week implies that you wi...   \n",
       "898  [Understanding the scenario: The question ment...   \n",
       "899  [The statement implies a sense of urgency., Pr...   \n",
       "\n",
       "                               correctness_annotations  \\\n",
       "0                 [correct, correct, correct, correct]   \n",
       "1    [correct, correct, correct, correct, correct, ...   \n",
       "2                 [correct, correct, correct, correct]   \n",
       "3               [correct, incorrect, correct, correct]   \n",
       "4    [correct, correct, correct, correct, correct, ...   \n",
       "..                                                 ...   \n",
       "895      [correct, correct, correct, correct, correct]   \n",
       "896  [correct, correct, correct, correct, correct, ...   \n",
       "897               [correct, correct, correct, correct]   \n",
       "898      [correct, correct, correct, correct, correct]   \n",
       "899  [correct, correct, correct, correct, correct, ...   \n",
       "\n",
       "                                 relevance_annotations answer_in_alignment  \\\n",
       "0             [relevant, relevant, relevant, relevant]                 yes   \n",
       "1    [relevant, relevant, relevant, relevant, relev...                 yes   \n",
       "2             [relevant, relevant, relevant, relevant]                 yes   \n",
       "3             [relevant, relevant, relevant, relevant]                 yes   \n",
       "4    [relevant, relevant, relevant, relevant, relev...                 yes   \n",
       "..                                                 ...                 ...   \n",
       "895  [relevant, relevant, relevant, relevant, relev...                 yes   \n",
       "896  [relevant, relevant, relevant, relevant, relev...                 yes   \n",
       "897           [relevant, relevant, relevant, relevant]                 yes   \n",
       "898  [relevant, relevant, relevant, relevant, relev...                 yes   \n",
       "899  [relevant, relevant, relevant, relevant, relev...                 yes   \n",
       "\n",
       "     true_answer pred_answer  \n",
       "0           True        True  \n",
       "1           True        True  \n",
       "2           True        True  \n",
       "3           True       False  \n",
       "4           True        True  \n",
       "..           ...         ...  \n",
       "895        False        True  \n",
       "896        False        True  \n",
       "897        False        True  \n",
       "898        False        True  \n",
       "899        False        True  \n",
       "\n",
       "[900 rows x 11 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert results to dataframe\n",
    "results_df = pd.DataFrame(res)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e31f56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json_to_filepath(data, filepath):\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "save_json_to_filepath(res, 'data/com2sense_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32447244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Keith is 5 feet tall so he is less likely to become an amateur basketball player than a horse jockey.\n",
      "['Being 5 feet tall is short for an amateur basketball player.', 'Being 5 feet tall is relatively tall for a horse jockey.', 'Therefore, a 5-foot-tall person is less likely to become a successful amateur basketball player than a horse jockey.', 'True']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Keith is 5 feet tall so he is less likely to become a novice basketball player than a horse rider.\n",
      "['Being 5 feet tall does not automatically disqualify someone from being a basketball player.', 'Horse riding does not have a strict height requirement like basketball does.', 'Therefore, it does not make sense to say that Keith being 5 feet tall makes him less likely to become a novice basketball player than a horse rider.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "With Sally needing to be at work in 5 minutes and Mark having 10 minutes to spare, it is more logical for Sally to hurry and skip doing the dishes.\n",
      "['Sally has a time constraint of 5 minutes to get to work.', 'Mark has a more flexible timeframe with 10 minutes to spare.', 'Doing the dishes would likely take more than 5 minutes.', 'Skipping the dishes allows Sally to meet her work obligation.', \"Mark's extra time allows him the flexibility to do the dishes without impacting his schedule.\", 'Prioritizing work over chores is generally considered logical when faced with a time constraint.', 'True']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "If you fold your linens correctly they are going to be creased when you place them on the bed.\n",
      "['Folding linens correctly typically involves creating neat, sharp creases.', 'When linens are folded correctly, they are less likely to have wrinkles and creases when placed on the bed.', 'Therefore, if you fold your linens correctly, they should not be creased when you place them on the bed.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Even if you fold your sheets properly, they will still be wrinkled when you put them on the bed.\n",
      "['Folding sheets properly typically reduces wrinkles.', 'However, wrinkles may still occur when sheets are used on a bed, especially if the sheets are made of a material that wrinkles easily or if they are not smoothed out before laying on the bed.', 'So, it is possible for properly folded sheets to still be wrinkled when put on the bed.', 'True.']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Even if you fold your sheets properly, they will still be wrinkled when you put them on the bed.\n",
      "['Folding sheets typically helps to minimize wrinkles compared to not folding them at all, as it keeps them organized and somewhat flat.', 'However, the type of fabric and the tightness of the fold can affect how wrinkled the sheets are after being folded.', 'Some fabrics are more prone to wrinkling than others, regardless of how carefully they are folded.', 'When sheets are placed on a bed, particularly if they are stretched and tucked in, any existing wrinkles from folding can be pulled out, or new wrinkles may be introduced depending on how the sheets are handled.', 'Properly folding sheets can reduce but not necessarily eliminate all wrinkles, especially if the fabric used easily wrinkles or if the sheets aren’t promptly unfolded and placed on the bed.', 'True']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Even if you fold your sheets properly, they will still be wrinkled when you put them on the bed.\n",
      "['Folding sheets typically helps to minimize wrinkles compared to not folding them at all, as it keeps them organized and somewhat flat.', 'However, the type of fabric and the tightness of the fold can affect how wrinkled the sheets are after being folded.', 'Some fabrics are more prone to wrinkling than others, regardless of how carefully they are folded.', 'When sheets are placed on a bed, particularly if they are stretched and tucked in, any existing wrinkles from folding can be pulled out, or new wrinkles may be introduced depending on how the sheets are handled.', 'Properly folding sheets can reduce but not necessarily eliminate all wrinkles, especially if the fabric used easily wrinkles or if the sheets aren’t promptly unfolded and placed on the bed.', 'True']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Even if you fold your sheets properly, they will still be wrinkled when you put them on the bed.\n",
      "['Properly folded sheets are less likely to be wrinkled than improperly folded sheets.', 'The act of putting sheets on a bed involves some amount of manipulation and movement.', 'This manipulation and movement can cause some wrinkling, even in carefully folded sheets.', 'Therefore, it is quite possible for even properly folded sheets to have some wrinkles after being put on a bed.', 'True']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "1 day after it is born, a cat is physically capable of reproducing.\n",
      "['Cats, like most mammals, require a gestational period before they are born.', 'Gestation in cats is approximately 63 days.', 'A newborn cat is not sexually mature.', 'Sexual maturity in cats takes several months, depending on breed and other factors.', 'Therefore, a one-day-old cat is physically incapable of reproduction.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "A cat is physically capable of reproducing just one day after it is born.\n",
      "['Cats, like most mammals, are born relatively underdeveloped compared to some other animals like many species of birds or reptiles.', \"Cats undergo a growth and maturation period after birth, which includes weaning from their mother's milk to solid food and a significant amount of physical and behavioral development.\", 'A key part of a cat’s development is reaching sexual maturity, which allows them to reproduce.', 'For domestic cats, sexual maturity typically occurs between 4 to 10 months of age, although this can vary slightly depending on factors like breed and individual health.', 'Considering that sexual maturity is not reached until several months after birth, a one-day-old kitten is incapable of reproduction.', 'Therefore, it is biologically impossible for a cat to reproduce one day after its birth, as it is far from reaching sexual maturity.', 'False']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "If you leap from the tenth story you can be hurt to death.\n",
      "['Leaping from a height increases the risk of injury due to the impact with the ground.', 'The tenth story of a building is a significant height, usually over 100 feet.', 'Falling from such a height typically results in severe injuries due to the high velocity of impact.', 'Severe injuries can include fatal injuries such as trauma to vital organs or the brain.', 'Therefore, leaping from the tenth story can indeed be fatal, aligning with common sense that it is extremely dangerous.', 'True']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Jumping from the tenth floor can result in fatal injuries.\n",
      "['Falling from a significant height generates substantial force due to gravity.', 'The force of impact increases with the height of the fall.', 'A ten-story building represents a considerable height.', 'The impact from such a fall would likely cause severe trauma to internal organs and bones.', 'Severe trauma from such a fall is highly likely to be fatal.', 'True']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Anna commutes to her job each day while Bry telecommutes, therefore Anna is less likely to encounter a punctured tire.\n",
      "[\"Anna's commute involves driving, while Bry's does not.\", 'Driving exposes a vehicle to more risks of tire punctures (e.g., road hazards).', \"Bry's telecommuter status means their vehicle is less exposed to these risks.\", \"Therefore, Anna's higher exposure to driving increases her likelihood of encountering a punctured tire compared to Bry.\", 'True']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "While Bry works from home, Anna drives to work every day, making her less likely to experience a flat tire.\n",
      "[\"Bry working from home does not affect Anna's likelihood of experiencing a flat tire.\", \"Driving to work every day may increase Anna's chances of getting a flat tire due to increased mileage.\", \"Therefore, the statement does not follow common sense because driving to work every day may actually increase Anna's likelihood of experiencing a flat tire.\", 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "While Bry works from home, Anna drives to work every day, making her less likely to experience a flat tire.\n",
      "['Consider the situation where Bry works from home and Anna drives to work every day.', 'Analyze what factors might influence the likelihood of experiencing a flat tire.', 'Recognize that the more a vehicle is used, the more likely it is to encounter road hazards or wear out its tires, potentially leading to a flat tire.', 'Understand that since Bry works from home, he likely uses his vehicle less frequently compared to Anna, who drives to work every day.', 'Conclude that Anna, driving daily, has a higher exposure to potential tire-damaging conditions such as potholes, debris, and regular wear and tear.', \"Evaluate if the question's statement that Anna is less likely to experience a flat tire holds true under the given circumstances.\", 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "While Bry works from home, Anna drives to work every day, making her less likely to experience a flat tire.\n",
      "['Consider the situation where Bry works from home and Anna drives to work every day.', 'Analyze what factors might influence the likelihood of experiencing a flat tire.', 'Recognize that the more a vehicle is used, the more likely it is to encounter road hazards or wear out its tires, potentially leading to a flat tire.', 'Understand that since Bry works from home, he likely uses his vehicle less frequently compared to Anna, who drives to work every day.', 'Conclude that Anna, driving daily, has a higher exposure to potential tire-damaging conditions such as potholes, debris, and regular wear and tear.', \"Evaluate if the question's statement that Anna is less likely to experience a flat tire holds true under the given circumstances.\", 'False']\n",
      "Incorrect step:  7\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Mike follows a vegan diet, whereas his wife Lisa does not, making it more probable for Lisa to choose meringue for dessert.\n",
      "['A meringue typically contains egg whites, which are animal products.', 'A vegan diet excludes all animal products including eggs.', 'Since Mike follows a vegan diet, he would avoid desserts containing egg whites, like meringues.', 'Lisa does not follow a vegan diet, implying she has no dietary restrictions concerning animal products.', 'This makes it more probable for Lisa, compared to Mike, to choose a dessert like meringue which contains animal products.', 'True']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "It's harder to compute a multi-digit multiplication problem with a calculator than by working it out by hand.\n",
      "['Calculators are designed to perform arithmetic operations, including multiplication.', 'Using a calculator for multi-digit multiplication is significantly faster and less prone to errors than manual calculation.', 'Manual calculation requires knowledge of multiplication tables, carrying digits, and careful organization of work.', 'The potential for human error is higher in manual calculation.', 'Therefore, the statement that it is harder to compute a multi-digit multiplication problem with a calculator than by hand is incorrect.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "It's more difficult to calculate a multi-digit multiplication problem with a calculator than by solving it manually.\n",
      "['Calculators are specifically designed to handle arithmetic computations quickly and accurately.', 'Manual calculations, especially for multi-digit numbers, require more time and are prone to errors compared to using a calculator.', 'Using a calculator typically involves simply entering the numbers and pressing the multiply operation key.', 'Manually solving a multi-digit multiplication problem involves knowledge of multiplication tables, alignment of digits, and potentially managing carries for each step of the multiplication.', 'Overall, solving multi-digit multiplication problems manually is more labor-intensive and error-prone than using a calculator.', 'False']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "It's more difficult to calculate a multi-digit multiplication problem with a calculator than by solving it manually.\n",
      "['Calculators are designed to perform arithmetic operations, including multiplication.', 'Manual multiplication involves following a specific algorithm, which can be prone to errors.', 'Calculators generally perform calculations much faster and with greater accuracy than humans.', 'The difficulty of manual multiplication increases significantly with the number of digits.', 'Using a calculator for multi-digit multiplication is significantly easier and less error-prone.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Working out a multi-digit multiplication problem by hand is easier than computing it with a calculator.\n",
      "['Consider the definition of \"easier\" in the context of performing mathematical calculations. Typically, \"easier\" means requiring less effort, time, and complexity.', 'Analyze the process of solving a multi-digit multiplication problem by hand. It requires understanding the algorithm (usually the standard multiplication algorithm), arranging the digits properly, performing multiple single-digit multiplications, adding intermediate results accurately, and checking for mistakes.', 'Contrast that with using a calculator. Operating a calculator generally involves simply entering the digits of the two numbers and pressing the multiplication key to get the result almost instantly.', 'Reflect on the common usage of calculators for complex calculations in both educational and professional settings, primarily due to their speed and accuracy.', 'Consider general human error and the time it takes to manually compute a multi-digit multiplication compared to the virtually instantaneous and error-free result from a calculator.', 'False']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "To play baseball without a baseball, a basketball is a better substitute than a tennis ball.\n",
      "['Playing baseball requires a ball to hit.', 'A basketball is larger and heavier than a tennis ball.', 'A basketball would more closely resemble the size and weight of a baseball compared to a tennis ball.', 'Therefore, a basketball would be a better substitute for playing baseball without a baseball than a tennis ball.', 'True']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "To play baseball without a baseball, a basketball is a better substitute than a tennis ball.\n",
      "['Consider the size and weight of the balls used in different sports: a baseball, a basketball, and a tennis ball.', 'A baseball is a small, hard ball designed for pitching and hitting with a bat.', 'A basketball is much larger and heavier than a baseball, and is designed to bounce and be thrown into hoops.', 'A tennis ball is smaller than a basketball and slightly larger than a baseball, lighter than a baseball, and designed for bouncing and hitting with a tennis racquet.', 'Using a basketball in a game of baseball would be challenging due to its size and weight, making it hard to pitch, hit, and catch effectively.', 'A tennis ball, though still not ideal, is closer in size to a baseball and lighter, which would allow it to be pitched, hit, and caught more easily than a basketball.', 'Therefore, in terms of substituting for a baseball in a baseball game, a tennis ball would be more manageable and practical compared to a basketball.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "To play baseball without a baseball, a basketball is a better substitute than a tennis ball.\n",
      "['Consider the size and weight of the balls used in different sports: a baseball, a basketball, and a tennis ball.', 'A baseball is a small, hard ball designed for pitching and hitting with a bat.', 'A basketball is much larger and heavier than a baseball, and is designed to bounce and be thrown into hoops.', 'A tennis ball is smaller than a basketball and slightly larger than a baseball, lighter than a baseball, and designed for bouncing and hitting with a tennis racquet.', 'Using a basketball in a game of baseball would be challenging due to its size and weight, making it hard to pitch, hit, and catch effectively.', 'A tennis ball, though still not ideal, is closer in size to a baseball and lighter, which would allow it to be pitched, hit, and caught more easily than a basketball.', 'Therefore, in terms of substituting for a baseball in a baseball game, a tennis ball would be more manageable and practical compared to a basketball.', 'False']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "To play baseball without a baseball, a basketball is a better substitute than a tennis ball.\n",
      "['Baseball requires a ball of a specific size and weight to be effectively thrown, hit, and caught.', 'A basketball is significantly larger and heavier than a baseball.', 'A tennis ball is smaller and lighter than a baseball.', \"While neither is a perfect substitute, a basketball's size and weight would make it harder to throw, hit, and catch with the same skill and accuracy as a baseball.\", 'A tennis ball would be easier to handle but might lack the appropriate weight and mass for a satisfactory baseball experience.', 'Considering the goal is to play a *similar* game to baseball, a tennis ball offers a closer approximation of the necessary properties than a basketball.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "To play baseball without a baseball, a basketball is a better replacement than a tennis ball.\n",
      "['Baseball requires a ball of a specific size and weight to be effectively thrown, hit, and caught.', 'A basketball is significantly larger and heavier than a baseball.', 'A tennis ball is smaller and lighter than a baseball.', \"While neither is ideal, a basketball's size and weight would make it much more difficult to throw, hit, and catch with the same mechanics as a baseball.\", 'A tennis ball would be closer in size, but still too small and light for proper baseball play.', 'Therefore, neither is a good replacement, but a tennis ball would be a slightly better, albeit still poor, replacement than a basketball due to its slightly smaller size and weight discrepancy.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "When playing baseball without an actual baseball, using a basketball is preferable to using a tennis ball.\n",
      "['Playing baseball requires hitting a ball with a bat.', 'A basketball is larger and heavier than a tennis ball, making it easier to hit with a bat.', 'A basketball is more similar in size and weight to a baseball compared to a tennis ball.', 'Therefore, using a basketball is preferable to using a tennis ball when playing baseball without an actual baseball.', 'True']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "When playing baseball without an actual baseball, using a basketball is preferable to using a tennis ball.\n",
      "['Consider the sizes of the balls: A baseball is significantly smaller than a basketball and closer in size to a tennis ball.', 'Consider the weight of the balls: A basketball is much heavier than a baseball, whereas a tennis ball is lighter but closer in weight.', 'Consider the typical use: Baseball requires precision in pitching and hitting, which is facilitated by a ball that can be easily thrown and hit precisely.', 'Impact on gameplay: Using a basketball could hinder the ability to pitch and hit effectively due to its size and weight.', 'Adaptability of the tennis ball: A tennis ball, being lighter and smaller, could be more feasibly substituted for a baseball than a basketball.', 'Potential damage and practicality: Using a basketball might also increase the risk of injury or damage to equipment due to its size and weight.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "When playing baseball without an actual baseball, using a basketball is preferable to using a tennis ball.\n",
      "['Consider the sizes of the balls: A baseball is significantly smaller than a basketball and closer in size to a tennis ball.', 'Consider the weight of the balls: A basketball is much heavier than a baseball, whereas a tennis ball is lighter but closer in weight.', 'Consider the typical use: Baseball requires precision in pitching and hitting, which is facilitated by a ball that can be easily thrown and hit precisely.', 'Impact on gameplay: Using a basketball could hinder the ability to pitch and hit effectively due to its size and weight.', 'Adaptability of the tennis ball: A tennis ball, being lighter and smaller, could be more feasibly substituted for a baseball than a basketball.', 'Potential damage and practicality: Using a basketball might also increase the risk of injury or damage to equipment due to its size and weight.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "When playing baseball without an actual baseball, using a basketball is preferable to using a tennis ball.\n",
      "['A basketball is significantly larger and heavier than a baseball.', 'A tennis ball is significantly smaller and lighter than a baseball.', 'In baseball, throwing and hitting require a certain weight and size for proper technique and distance.', \"A basketball's size and weight would make throwing and hitting more difficult, potentially dangerous, and less like actual baseball.\", \"A tennis ball's smaller size and lighter weight would also make it less suitable, leading to less realistic practice.\", 'While neither is ideal, a basketball presents more challenges and potential safety issues compared to a tennis ball.', 'False']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "When playing baseball without an actual baseball, using a basketball is preferable to using a tennis ball.\n",
      "['A basketball is significantly larger and heavier than a baseball.', 'A tennis ball is significantly smaller and lighter than a baseball.', 'In baseball, throwing and hitting require a certain weight and size for proper technique and distance.', \"A basketball's size and weight would make throwing and hitting more difficult, potentially dangerous, and less like actual baseball.\", \"A tennis ball's smaller size and lighter weight would also make it less suitable, leading to less realistic practice.\", 'While neither is ideal, a basketball presents more challenges and potential safety issues compared to a tennis ball.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Young working couples are more inclined to plan a picnic on Sundays rather than on Mondays.\n",
      "['Sunday is generally recognized as a weekend day in many regions around the world.', 'Most working individuals, including young couples, typically have weekends off, making them free from work commitments.', 'Monday, on the other hand, is usually the start of the workweek for many people.', 'Planning leisure activities like picnics requires free time, which is more available on non-working days.', 'Therefore, young working couples would logically prefer to plan picnics on a day when they are more likely to be off work.', 'Given that Sundays are commonly a day off work and Mondays are a working day, it follows that young working couples would be more inclined to plan picnics on Sundays.', 'True']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Young working couples are more inclined to plan a picnic on Sundays rather than on Mondays.\n",
      "['Most people work Monday through Friday.', 'Sundays are typically a day off for most working people.', 'Mondays are typically a workday for most working people.', 'A picnic requires free time.', 'Young working couples are more likely to have free time on Sundays than on Mondays.', \"Therefore, it's more likely that young working couples would plan a picnic on a Sunday.\", 'True']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Given his two-thousand-dollar monthly income and no savings, he cannot afford a housing rent of two thousand dollars.\n",
      "['Consider his monthly income: two-thousand dollars.', 'Compare the monthly income to his housing costs: also two-thousand dollars.', 'Recognize that having a housing rent equal to his entire monthly income leaves no room for other expenses like food, transportation, utilities, or emergencies.', \"Understand that typical financial advice suggests that housing should not exceed 30% of one's income to maintain a balanced budget.\", 'Acknowledging that spending 100% of his income on rent is unsustainable and impractical in a real-world scenario.', 'True']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Given his two-thousand-dollar monthly earnings and no savings, he cannot manage a housing rent of two thousand dollars.\n",
      "['We know that his monthly earnings are two thousand dollars.', 'The stated housing rent is also two thousand dollars.', 'Managing this rent would mean he would have no money left for any other expenses such as food, utilities, transportation, and healthcare.', 'Furthermore, he has no savings, which means he does not have additional funds to draw from for any other expenses or emergencies.', \"It is generally advised that housing costs should not exceed 30% of one's income to maintain a manageable budget for all other living expenses.\", 'False']\n",
      "Incorrect step:  5\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "She can squat one hundred pounds so she cannot lift the twenty pound box.\n",
      "['Squatting one hundred pounds requires leg strength, while lifting a twenty pound box requires arm strength.', 'The fact that she can squat one hundred pounds does not necessarily mean she cannot lift a twenty pound box.', 'Different muscles are used for squatting and lifting.', 'False']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "She can squat one hundred pounds so she cannot lift the twenty pound box.\n",
      "['The question claims that if someone can squat one hundred pounds, then they cannot lift a twenty pound box.', 'Squatting one hundred pounds indicates a significant level of strength, particularly in the lower body and core.', 'Lifting a twenty pound box mostly involves upper body strength, but the strength displayed by squatting one hundred pounds suggests a general physical capability.', 'Typically, someone who can squat one hundred pounds would have no difficulty lifting a twenty pound box, as it requires less strength.', 'Thus, the statement that she cannot lift the twenty pound box despite being able to squat one hundred pounds is logically inconsistent unless there are specifics and conditions not mentioned that would prevent her from doing so.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Because she can squat one hundred pounds, she is unable to lift the twenty-pound box.\n",
      "['The ability to squat one hundred pounds demonstrates a significant level of strength, especially in the lower body.', 'Lifting a twenty-pound box primarily involves upper body strength, but also requires some lower body strength.', 'If a person can squat one hundred pounds, it logically follows that their overall strength, both upper and lower body, is likely more than adequate to handle lighter weights.', 'A twenty-pound box is significantly lighter than one hundred pounds.', 'It follows that if someone can manage to squat one hundred pounds, lifting a twenty-pound box should be well within their capabilities, unless there are other limiting factors not mentioned in the question.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Because she can squat one hundred pounds, she is unable to lift the twenty-pound box.\n",
      "[\"The statement claims a person's ability to squat 100 pounds prevents them from lifting a 20-pound box.\", 'Squatting and lifting are different movements requiring different muscle groups and techniques.', 'The ability to perform a more demanding exercise (squatting 100 pounds) logically implies the ability to perform a less demanding exercise (lifting 20 pounds).', 'The statement contradicts common sense and basic physical ability.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Since Sherry needs to complete her grocery shopping prior to visiting the library, the bank, and the post office, she will carry a cooler to store her ice cream in.\n",
      "['Sherry needs to complete grocery shopping before visiting the library, bank, and post office.', 'Carrying a cooler for ice cream storage is not necessary for completing these errands.', 'It is more practical to wait until the end of her errands to purchase ice cream.', 'Therefore, it is false that Sherry will carry a cooler for her ice cream.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Not wanting to get separated with her family, she accepted the job 500 miles away from home and declined the one 20 miles away.\n",
      "['The person values staying close to her family, as evidenced by not wanting to get separated from them.', 'Accepting the job 500 miles away from home would likely mean being separated from her family for extended periods of time.', 'Declining the job 20 miles away would allow her to stay closer to her family.', 'True']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "She accepted the job 500 miles away from home and turned down the one 20 miles away because she didn't want to be separated from her family.\n",
      "['She accepted a job 500 miles away from home, which is a significant distance.', 'This suggests that distance from home was not a primary factor in her decision-making process.', 'Therefore, the statement that she turned down a job 20 miles away to avoid being separated from her family does not follow common sense.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "She accepted the job 500 miles away from home and turned down the one 20 miles away because she didn't want to be separated from her family.\n",
      "['She accepted a job 500 miles away from home, which is a significant distance.', 'This suggests that distance from home was not a primary factor in her decision-making process.', 'Therefore, the statement that she turned down a job 20 miles away to avoid being separated from her family does not follow common sense.', 'False']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Expecting to pay one hundred dollars for the dress, Susan was excited to purchase one with twenty percent off.\n",
      "['The question describes a common scenario: a shopper finding a discount on an item they want to buy.', 'The price of the dress ($100) is a realistic price for a dress.', 'A 20% discount is also a reasonable discount offered in stores.', \"Susan's excitement at finding a discount is a logical reaction.\", 'True']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Al is a painter and Sam is an accountant. Al is more likely to work at a desk.\n",
      "['Al is a painter, which typically involves physical work such as painting walls or canvases.', 'Sam is an accountant, which typically involves working at a desk with numbers and financial documents.', 'Based on their professions, it is more likely that Sam, the accountant, would work at a desk.', 'True']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Al is a painter and Sam is an accountant. Al is more likely to work at a desk.\n",
      "['Al is identified as a painter, which usually involves working with canvases, paint, and possibly easels.', 'Sam is identified as an accountant, a profession typically associated with working at computers, with files, and extensive paperwork, usually at a desk.', 'The nature of painting can be quite varied; while some administrative tasks may require a desk, much of a painter’s work is done in a studio or outside, not primarily at a desk.', 'Accountancy generally involves desk-based activities like data entry, calculations, and preparation of financial statements and reports.', 'Comparing the typical work environments, an accountant would naturally spend more time at a desk than a painter.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Al is an artist and Sam is a bookkeeper. Al is more probable to work at a desk.\n",
      "['Al is an artist, so it is possible that he works at a desk.', 'Sam is a bookkeeper, which means he is more likely to work at a desk compared to Al.', 'Based on their professions, it is more probable for Sam to work at a desk than Al.', 'True']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Jack had to wake up for church early on Sunday morning, so he went drinking Saturday night instead of going to sleep early.\n",
      "['The question states Jack needed to wake up early Sunday for church.', 'Logically, to wake up early, one would go to sleep early the night before.', 'Instead, Jack went drinking Saturday night.', 'Drinking alcohol often interferes with sleep quality and quantity.', \"Therefore, Jack's actions directly contradict his need to wake up early.  This is illogical and lacks common sense.\", 'False']\n",
      "Incorrect step:  4\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Gregory began working at the shop when he was eighteen. In two decades, he is in fundamental training.\n",
      "[\"Consider Gregory's age at the start: eighteen.\", 'Add two decades (twenty years) to his initial age of eighteen, which brings him to thirty-eight.', '\"Fundamental training\" typically refers to an introductory level of training, often associated with new recruits in various fields such as military or job-related skills.', 'It is uncommon for someone to begin fundamental training at the age of thirty-eight as most fundamental training programs target younger individuals, especially in physically demanding areas like the military.', 'Therefore, the scenario described implies an unusual career path or late training start, which does not align with typical career progression norms or common sense related to age and training.', 'False']\n",
      "Incorrect step:  3\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "I have time to run next door and water my neighbor's plants because my laundry will be done in 2 minutes instead of 20.\n",
      "[\"Running next door to water neighbor's plants will take time.\", 'Laundry will only take 2 more minutes to finish.', 'It makes sense to wait 2 more minutes for laundry instead of taking time to water plants.', 'False']\n",
      "Incorrect step:  2\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Even if the late fee is only 10 dollars, it is better to pay nothing in late fees than a ten-dollar late fee.\n",
      "['Late fees are typically charged because a payment was not made on time.', 'Accumulating late fees can lead to a negative impact on credit score and financial standing.', 'Paying nothing in late fees means avoiding any negative consequences.', 'Paying a ten-dollar late fee may not have a significant impact compared to accumulating multiple late fees.', 'False']\n",
      "Incorrect step:  1\n",
      "Question:  Evaluate if the following Q follows common sense. Answer 'True' or 'False'\n",
      "Even if the late fee is only 10 dollars, it is better to pay nothing in late fees than a ten-dollar late fee.\n",
      "['Late fees are typically charged because a payment was not made on time.', 'Accumulating late fees can lead to a negative impact on credit score and financial standing.', 'Paying nothing in late fees means avoiding any negative consequences.', 'Paying a ten-dollar late fee may not have a significant impact compared to accumulating multiple late fees.', 'False']\n",
      "Incorrect step:  2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(results_df)):\n",
    "    assert len(results_df.loc[i, 'correctness_annotations']) == len(results_df.loc[i, 'relevance_annotations'])\n",
    "    # count how many 'incorrect' are in correctness annotations\n",
    "    incorrect_count = 0\n",
    "    irrelevant_count = 0\n",
    "    for j, correctness in enumerate(results_df.loc[i, 'correctness_annotations']):\n",
    "        if correctness == 'incorrect':\n",
    "            print('Question: ', results_df['question'][i])\n",
    "            print([step for step in results_df['cot_steps'][i]])\n",
    "            print('Incorrect step: ', j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d50179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
