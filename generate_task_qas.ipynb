{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU1jVaKp9xgl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import requests\n",
        "from pathlib import Path\n",
        "import importlib.util"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and parse JSON from URL\n",
        "def load_json_url(url: str):\n",
        "    return requests.get(url).json()\n",
        "\n",
        "# Fetch piCom2Sense (100 samples)\n",
        "def fetch_com2sense(num_samples=100) -> list:\n",
        "    url = \"https://raw.github.com/google/BIG-bench/main/bigbench/benchmark_tasks/com2sense/big-bench-data.json\"\n",
        "    task_data = load_json_url(url)\n",
        "    data = task_data[\"examples\"]\n",
        "    selected = random.sample(data, num_samples)\n",
        "    com2sense_samples = [{\n",
        "            \"id\": f\"com2sense_{i}\",\n",
        "            \"task\": \"com2sense\",\n",
        "            \"question\": sample[\"sent\"],\n",
        "            \"answer\": sample[\"label\"] == \"True\"\n",
        "        } for i, sample in enumerate(selected)]\n",
        "    return com2sense_samples\n",
        "\n",
        "# Fetch Cause and Effect (100 samples)\n",
        "def fetch_cause_effect(num_samples=100) -> list:\n",
        "    url = \"https://raw.githubusercontent.com/google/BIG-bench/main/bigbench/benchmark_tasks/cause_and_effect/one_sentence_no_prompt/task.json\"\n",
        "    task_json = load_json_url(url)\n",
        "    samples = []\n",
        "    for ex in task_json[\"examples\"]:\n",
        "        for sentence, score in ex[\"target_scores\"].items():\n",
        "            samples.append({\n",
        "                \"id\": f\"cause_effect_{len(samples)}\",\n",
        "                \"task\": \"cause_effect\",\n",
        "                \"question\": sentence,\n",
        "                \"answer\": score == 1.0\n",
        "            })\n",
        "    cause_effect_samples = random.sample(samples, num_samples)\n",
        "    return cause_effect_samples\n",
        "\n",
        "# Generate Web of Lies samples (100 samples)\n",
        "def generate_web_of_lies(num_samples=100, num_sentences_per_sample=4) -> list:\n",
        "    # Retrieve method to generate a Web of Lie sample\n",
        "    def load_web_of_lies_task():\n",
        "        # Download original script\n",
        "        url = \"https://raw.githubusercontent.com/google/BIG-bench/main/bigbench/benchmark_tasks/web_of_lies/task.py\"\n",
        "        code = requests.get(url).text\n",
        "\n",
        "        # Patch out the bigbench import and task.Task inheritance\n",
        "        patched_lines = []\n",
        "        for line in code.splitlines():\n",
        "            if \"import bigbench.api.task\" in line:\n",
        "                continue\n",
        "            if \"class WebOfLiesTask(task.Task):\" in line:\n",
        "                patched_lines.append(\"class WebOfLiesTask(object):\")\n",
        "            else:\n",
        "                patched_lines.append(line)\n",
        "\n",
        "        path = Path(\"task_web_of_lies.py\")\n",
        "        path.write_text(\"\\n\".join(patched_lines))\n",
        "\n",
        "        # Dynamically import patched module\n",
        "        spec = importlib.util.spec_from_file_location(\"web_of_lies\", path)\n",
        "        mod = importlib.util.module_from_spec(spec)\n",
        "        spec.loader.exec_module(mod)\n",
        "        return mod.WebOfLiesTask()\n",
        "\n",
        "    # Generate 100 samples\n",
        "    task = load_web_of_lies_task()\n",
        "    web_of_lies_samples = []\n",
        "    for i in range(num_samples):\n",
        "        q, a = task._get_expression(num_sentences_per_sample)\n",
        "        web_of_lies_samples.append({\n",
        "            \"id\": f\"web_of_lies_{i}\",\n",
        "            \"task\": \"web_of_lies\",\n",
        "            \"question\": q,\n",
        "            \"answer\": a\n",
        "        })\n",
        "    return web_of_lies_samples\n",
        "\n",
        "# Fetch Arithmetic (100 samples)\n",
        "def fetch_arithmetic(num_samples=100) -> list:\n",
        "    url = \"https://raw.githubusercontent.com/google/BIG-bench/main/bigbench/benchmark_tasks/arithmetic/5_digit_multiplication/task.json\"\n",
        "    data = load_json_url(url)\n",
        "    samples = random.sample(data[\"examples\"], num_samples)\n",
        "    arithmetic_samples = [{\n",
        "        \"id\": f\"arithmetic_{i}\",\n",
        "        \"task\": \"arithmetic\",\n",
        "        \"question\": ex[\"input\"],\n",
        "        \"answer\": int(ex[\"target\"])\n",
        "    } for i, ex in enumerate(samples)]\n",
        "    return arithmetic_samples"
      ],
      "metadata": {
        "id": "Vtfusf13-CKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all and save\n",
        "def build_unified_dataset(num_samples_per_task=100):\n",
        "    data = (\n",
        "        fetch_com2sense(num_samples_per_task) +\n",
        "        fetch_cause_effect(num_samples_per_task) +\n",
        "        generate_web_of_lies(num_samples_per_task) +\n",
        "        fetch_arithmetic(num_samples_per_task)\n",
        "    )\n",
        "    with open(\"unified_bigbench_4x100.json\", \"w\") as f:\n",
        "        json.dump(data, f, indent=2)\n",
        "    print(\"✅ Saved unified_bigbench_4x100.json\")"
      ],
      "metadata": {
        "id": "Ver0UI7l--kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_unified_dataset(num_samples_per_task=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UQl2xhrIn9X",
        "outputId": "843c721d-ebaf-4be8-a6a0-a31fa59a8b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved unified_bigbench_4x100.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arithmetic_samples[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZU6fA8IB4Pw",
        "outputId": "b6c409c1-20fe-41f3-f7ae-2b548b040810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'arithmetic_0',\n",
              "  'task': 'arithmetic',\n",
              "  'question': 'What is 22814 times 78923?',\n",
              "  'answer': 1800549322},\n",
              " {'id': 'arithmetic_1',\n",
              "  'task': 'arithmetic',\n",
              "  'question': 'What is 65511 times 33321?',\n",
              "  'answer': 2182892031}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "web_of_lies_samples[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlyPPLiyGHUD",
        "outputId": "0ab3c80e-f0e3-45bc-b8c8-f158ef3b8169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'web_of_lies_0',\n",
              "  'task': 'web_of_lies',\n",
              "  'question': 'Kandi tells the truth. Raymond says Kandi lies. Gwenn says Raymond tells the truth. Delfina says Gwenn lies. Does Delfina tell the truth?',\n",
              "  'answer': True},\n",
              " {'id': 'web_of_lies_1',\n",
              "  'task': 'web_of_lies',\n",
              "  'question': 'Ka tells the truth. Michaela says Ka lies. Lorine says Michaela tells the truth. Shalonda says Lorine lies. Does Shalonda tell the truth?',\n",
              "  'answer': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "causeeffect_samples[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDWEIOXc-COw",
        "outputId": "2ec1d687-4c18-49aa-bffe-59debc5030ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'cause_effect_10',\n",
              "  'task': 'cause_effect',\n",
              "  'question': 'The boy lifted his eyes from the book because there was a loud noise.',\n",
              "  'answer': True},\n",
              " {'id': 'cause_effect_82',\n",
              "  'task': 'cause_effect',\n",
              "  'question': 'My friend celebrated with their family because my friend got a promotion.',\n",
              "  'answer': True}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "com2sense_samples[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfkWuX-nBMme",
        "outputId": "35695aff-b511-4c50-dc7d-bc83db1fdec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'com2sense_0',\n",
              "  'task': 'com2sense',\n",
              "  'question': \"It's easier to make more money in the stock market after 3 years than after 1 month.\",\n",
              "  'answer': True},\n",
              " {'id': 'com2sense_1',\n",
              "  'task': 'com2sense',\n",
              "  'question': 'If you have a cold, it is less accurate to stick a thermometer under your tongue instead of over your tongue.',\n",
              "  'answer': False}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}